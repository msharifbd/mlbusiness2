{"title":"<center> Exploratory Data Analysis in Python","markdown":{"yaml":{"title":"<center> Exploratory Data Analysis in Python","format":{"html":{"toc":true,"toc-title":"Table of Contents","toc-depth":5,"number-sections":true,"mainfont":"emoji"}},"engine":"knitr"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| include: false\nlibrary(reticulate)\nSys.unsetenv(\"RETICULATE_PYTHON\")\nreticulate::use_virtualenv(\"C:\\\\Users\\\\mshar\\\\OneDrive - Southern Illinois University\\\\BSAN405_MLINBUSINESS_WEBSITE\\\\mlbusiness2\")\n```\n\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The objective of this document is to introduce the necessary functions from `pandas` library in `Python` for data manipulation and `matplotlib` and `seaborn` libraries for data visualization. There are basically six functions - `select()`, `filter()`, `mutate()`, `arrange()`, `group_by()`, and `summarize()` - from `dplyr` package of `tidyverse` ecosystem that are very much necessary for data manipulation. These six functions can be used for 80% of data manipulation problems. In this document, we will compare the above six functions from `dplyr` with the equivalent `pandas` functions. Additionally, this handout also compares some other Python packages, particularly `plotnine` library that can be used to apply `ggplot` in Python.\n\n\n# Loading Necessary Python Packages \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Python` programming in `RMarkdown` is used to analyse the data. In some cases, the `R Programming`is also used. In this section, the necessary `python` packages/modules are imported. \n\n```{python}\n#| warning: false\nimport pandas as pd # For Data Manipulation\nimport numpy as np # For Data Manipulation\nimport matplotlib.pyplot as plt # For Visualization \n\nimport seaborn as sns # For Visualization \nimport sklearn # For Machine Learning \n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n# Plotnine is a clone of ggplot2 in R\nfrom plotnine import *\n# lets-plot is another clone of ggplot2\n# from lets_plot import *\n```\n\n\n# Setting/Changing Working Directory \n\n```{python}\n#| eval: false\nimport os\nos.getcwd()\nos.listdir()\n```\n\n\n# Importing the Dataset \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Being able to import the dataset into your text editor or IDE such as VS Code or RStudio is an important data analytics skill. Data reside in many places and in many forms. Different kinds of data from different sources need to be imported. For example - you can import a dataset from your local machine or website or database. Sometimes, we need to import data from social media such as Twitter, Youtube and Facebook. Therefore, knowing how to import data from many different sources is a very critical skill of data scientists. \n\n\n```{python}\n# Importing Dataset \nproduct = pd.read_csv(\n  \"https://raw.githubusercontent.com/msharifbd/DATA/main/Al-Bundy_raw-data.csv\")\n\n```\n\n# Learning About the Metadata \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Metadata is data about data. Once we import a dataset into our text editor, we need to study the dataset very well. For example - we need to know how many features and cases the dataset has. We also need to know the types of the features. Many types the features are not in appropriate type; then, we need to change them into appropriate type. Moreover, we need to check whether the dataset contains missing data and make decision about how to deal with those missing data. To sum up, learning about the metadata is a very important step before you start processing your data.\n\n\n```{python}\n# Metadata of the dataset \nproduct.shape\n\nprint('The total number of rows and columns of the product data is \\\n{} and {} respectively.'.format(product.shape[0], product.shape[1]))\n\nproduct.count()[0] # counting the number of rows in the dataset\n\n```\n\n\n\n```{python}\nproduct.columns\nproduct.dtypes\n```\n\n\n\n```{python}\nproduct.head()\n```\n\n```{python}\nproduct.info()\n```\n\n# Cleaning the Dataset \n\n```{python}\n# Changing the names of the columns to uppercase \nproduct.rename(columns = str.upper, inplace = True)\nproduct.columns\n```\n\n\n```{python}\nnew_column = product.columns \\\n    .str.replace(\"(\", '').str.replace(\")\", \"\") \\\n    .str.replace(' ','_') # Cleaning the names of the variables \nnew_column\n```\n\n```{python}\n# Replacing whitespace in the names of the variables \ncol_name = product.columns.str.replace(' ','_')\nproduct.info()\n```\n\n\n\n```{python}\nproduct.columns = new_column # Changing all column names \nproduct.info()\nproduct.head()\n```\n\n\n## Changing the Types of the Variables \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are several types of data in Python as it is in R. Table @tbl-table1 lists the data types in python.\n\n```{r}\n#| include: false\nlibrary(kableExtra)\ndata_types = tibble::tribble(\n  ~`Python Data Type`, ~`Data Nature`, \n  'float64', 'Real Numbers',\n  'category', 'cateogries',\n  'datetime64', 'Date Times',\n  'int64', 'Integers',\n  'bool', 'True or False',\n  'string', 'Text'\n)\n\n\n```\n\n\n```{r}\n#| label: tbl-table1\n#| echo: false\n# These are R code to prepare Table 2 using KableExtra \nkbl(data_types, booktabs = TRUE, \n    caption = \"Types of Data in Python\") %>% \n  kable_styling(latex_options = c ('striped', 'hold_positions'))\n```\n\n\n\n\n```{python}\n# Changing the DATE variable from object to date\nproduct['DATE'] = pd.to_datetime(product['DATE']) \nproduct.info()\n```\n\n```{python}\n# converting integer to object\nproduct.INVOICENO = product.INVOICENO.astype(str) \nproduct[['MONTH', 'PRODUCTID']] = product[['MONTH', 'PRODUCTID']].astype(str) \nproduct.info()\n```\n\n# `Tidyverse` and `Pandas` Eqivalent Functions \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table @tbl-table2 compares the `tidyverse` and `pandas` equivalent functions. These functions are very much important to perform data analysis in both `R` and `Python`. \n\n```{r}\n#| include: false\ntidyverse_pandas = tibble::tribble(\n  ~`tidyverse function`, ~`pandas function`, \n  'filter ()', 'query ()',\n  'arrange ()', 'sort_values ()',\n  'select ()', 'filter () or loc ()',\n  'rename ()', 'rename ()',\n  'mutate ()', 'assign ()',\n  'group_by ()', 'groupby ()',\n  'summarize ()', 'agg ()'\n)\n\n```\n\n```{r}\n#| echo: false\n#| label: tbl-table2\n# These are R code to prepare Table 2 using KableExtra \nkbl(tidyverse_pandas, booktabs = TRUE, \n    caption = \"Tidyverse and Pandas Equivalent Functions\") %>% \n  kable_styling(latex_options = c ('striped', 'hold_positions'))\n```\n\n\n## `select ()` Equivalent in Python - Accessing Columns \n\n```{python}\nprod2 = product[['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\nprod2.head()\n```\n\n\n```{python}\nproduct.loc[:,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\n\nproduct.loc[0:5,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\n```\n\n\n\n```{python}\nproduct.filter(['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE'])\n```\n\n```{python}\n# Regular Expression (Regex)\nproduct.filter(regex = \"PRICE$\") # Ends with Price \nproduct.filter(regex = \"^SIZE\")  # Starts with SIZE\nproduct.filter(regex = \"PRICE\")  # Contains the word Price \n```\n\n\n\n```{python}\nproduct.select_dtypes('object')\nproduct.select_dtypes('int')\n```\n\n\n```{python}\nproduct.loc[:,product.columns.str.startswith('SIZE')]\nproduct.loc[:,product.columns.str.contains('PRICE')]\nproduct.loc[:,product.columns.str.endswith('PRICE')]\n```\n\n\n\n```{python}\n# Dropping some columns \nproduct.info()\nproduct.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1)\nproduct.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1) \\\n    .pipe(lambda x: x.info())\n```\n\n### Rearranging Columns \n\n```{python}\n# Sorting Alphabetically\nproduct.reindex(sorted(product.columns), axis = 1)\n# Sorting As You Want (ASY)\nproduct.columns.to_list()\ncol_first = ['YEAR','MONTH']\ncol_rest = product.columns.difference(col_first, sort=False).to_list()\nproduct2 = product[col_first + col_rest]\nproduct2.info()\n```\n\n\n## `filter ()` Equivalent in Python - Accessing Rows \n\n```{python}\nproduct.info()\nproduct.COUNTRY.value_counts()\nproduct['YEAR'].unique()\nproduct['YEAR'].value_counts()\n```\n\n\n```{python}\nproduct.query('COUNTRY == \"United States\"')\nproduct.query('COUNTRY == \"United States\" | COUNTRY == \"Canada\"')\nproduct.query(\"COUNTRY in ['United States', 'Canada']\")\n\nproduct.query(\"COUNTRY == 'United States' & YEAR == 2016\")\nproduct.query(\"COUNTRY == 'United States' & YEAR in [2015,2016]\")\n```\n\n\n\n```{python}\nproduct.loc[(product['COUNTRY'] == \"United States\")]\nproduct.loc[product['COUNTRY'].isin([\"United States\", \"Canada\"])]\nproduct.loc[product['COUNTRY'] \\\n  .isin([\"United States\", \"Canada\"]) & (product['YEAR'] == 2014)]\nproduct.loc[(product['COUNTRY'] == \"United States\") & (product[\"YEAR\"] == 2014)]\n```\n### `loc[]` Function can be used both for Slicing (selecting Rows) and Selecting Columns\n\n```{python}\nproduct.loc[\n  product['COUNTRY'] == 'United States',\n  ['COUNTRY', \"UNITPRICE\", \"SALEPRICE\"]]\n```\n\n## `arrange ()` Equivalent in Python - Sorting or Arranging Rows \n\n```{python}\nproduct.sort_values(by = ['MONTH'])\nproduct.sort_values(by = ['MONTH'], ascending = False)\nproduct.sort_values(by = ['MONTH', 'SALEPRICE'])\n```\n\n## `rename ()` Equivalent in Python - Renaming Column Names\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We already did some renaming of the columns using `str.` function. Here we use `rename ()` function to change the name of the columns. \n\n```{python}\nproduct.info()\nproduct.rename( columns = \n  {'SIZE_(EUROPE)': 'SIZE_EUROPE',\n   'SIZE_(UK)' : 'SIZE_UK'}) \\\n   .pipe(lambda x: x.info())\n```\n\n## `mutate ()` Equivalent in Python - Creating New Columns (Variables)\n\n```{python}\nproduct['NECOLUMN'] = 5\nproduct.head()\nproduct.drop(columns = ['NECOLUMN'], axis = 1, inplace = True) \n```\n\n\n```{python}\nproduct['SALEPRICE2'] = product['UNITPRICE']*(1-product['DISCOUNT'])\nproduct.info()\n```\n\n\n```{python}\n# Using the assign () function \nproduct[['PRODUCTID', 'UNITPRICE', 'DISCOUNT']] \\\n .assign(SALEPRICE3 = lambda x: x.UNITPRICE*(1-x.DISCOUNT)) \\\n .head(5)\n```\n\n## `group_by ()` and `summarize ()` Equivalent in Python - Summarizing Data \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Figure @fig-groupbyplot presents the split-apply-combine principle in `group_by ()` and `summarize ()` functions. \n\n\n```{r}\n#| echo: false\n#| label: fig-groupbyplot\n#| fig-cap: \"Split Apply and Combine Principle\"\n#| fig-align: center\nknitr::include_graphics(\"images/split-apply-combine.png\")\n```\n\n\n```{python}\nproduct.info()\nproduct.groupby(['COUNTRY']) ['UNITPRICE'].mean()\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']].mean()\n\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(np.mean)\n\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(\"mean\")\n       \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"))\n            \n            \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"),\n            TOTALN = (\"SALEPRICE\", \"size\"), # size function for n\n            TOTALOBS = (\"SALEPRICE\", \"count\") # count function for n\n            )\n\n\n# Combining Several Pandas Functions together           \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"),\n            TOTALN = (\"SALEPRICE\", \"size\"), # size function for n\n            TOTALOBS = (\"SALEPRICE\", \"count\") # count function for n\n            ) \\\n       .sort_values(by = ['TOTALOBS'], ascending = False) \\\n       .reset_index() \\\n       .query ('COUNTRY == \"United States\"')\n\n```\n\n\n## Summary Statistics in Python \n\n```{python}\n# Summary Statistics in Python \nproduct.GENDER.value_counts()\n# Encoding a Categorical Variables \nproduct['SEX'] = product['GENDER'].map({\n  'Male':1,\n  'Female':0\n})\n\n\n# Defining a Function \ndef percentile(n):\n    def percentile_(x):\n        return x.quantile(n)\n    percentile_.__name__ = 'percentile_{:02.0f}'.format(n*100)\n    return percentile_\n  \nproduct [['SALEPRICE', 'UNITPRICE', 'SEX']] \\\n     .agg([\"count\",\"mean\", \"std\", \"median\", percentile(0.25), percentile(0.75)]) \\\n     .transpose () \\\n     .reset_index() \\\n     .rename(columns = {'index': \"Variables\",\n                        'percentile_25': 'P25',\n                        'percentile_75': 'P75',\n                        'count': 'n',\n                        'mean' : 'Mean',\n                        'median' : 'Median',\n                        'std': 'Std'\n                       }) \\\n      .round(3) # rounding to two decimal places \n\n```\n\n\n\n# Reshaping Data \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Two functions are widely used in python to reshape data. These functions are - `melt ()` and `pivot ()`, which are equivalent to `pivot_longer ()` and `pivot_wider ()` in R. \n\n```{python}\npd.__version__ # 2.2.3\n```\n\n\n```{python}\nproduct[['PRODUCTID','GENDER']].value_counts()\n\nreshape = product[['PRODUCTID','GENDER']] \\\n          .value_counts() \\\n          .reset_index(name = 'COUNTS') \\\n          .pivot(index = 'PRODUCTID', columns = 'GENDER', values = \"COUNTS\") \\\n          .assign (TOTALSALES = lambda x: x.Female + x.Male) \\\n          .sort_values (by = ['TOTALSALES'], ascending = False) \\\n          .reset_index() \n          \nreshape.head(5)\n```\n\n\n# Data Visualization \n\n## Bar Chart \n```{python}\n#| warning: false\n#| fig-align: center\n#| fig-cap: \"Total Observations of Countries\"\n\nbar_r = product.filter (['COUNTRY']) \\\n       .value_counts() \\\n       .reset_index() \\\n       .rename (columns = {'count':'n'}) \\\n       .sort_values (by = ['n'])\n\n(ggplot(data = bar_r, \n  mapping = aes(x = 'COUNTRY', y = 'n'))+\n  geom_bar (fill = \"pink\", stat = \"identity\")+\n  labs (x = 'Country',\n  y = 'Number of Observations'\n  #,title = 'Total Observations of Countries'\n  )\n)\n\n```\n\n## Line Chart \n\n```{python}\n#| warning: false\n#| fig-cap: \"Relations between Shoe Size and Sale Price in Different Countries\"\n#| fig-align: center\n\n(ggplot(product, aes(x = 'SIZE_US', y= 'UNITPRICE', color = 'GENDER'))+\n facet_wrap('COUNTRY')+\n geom_smooth(se = False, method = 'lm')+\n labs(x = \"Shoe Size (US)\", y = \"Price\")+\n theme (legend_position = \"top\")\n)\n\n```\n\n```{python}\n#| warning: false\n#| fig-cap: \"Sales of Shoe in Different Months\"\n#| fig-align: center\n\nmonth_sales = product['MONTH'] \\\n    .value_counts(sort = False) \\\n    .reset_index(name = 'SALES') \\\n    .rename (columns = {'index' : 'MONTH'})\n\nmonth_sales['MONTH'] = pd.to_numeric(month_sales['MONTH']) \n\n(ggplot(month_sales, aes (\"MONTH\", \"SALES\"))\n + geom_point(color = 'blue')\n + labs(x = \"Month\", y = \"Total Sales\"\n   #,title = \"SALES IN DIFFERENT MONTHS\"\n   )\n)\n```\n\n# Conclusion \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data science is the number 1 most promising job in the US in recent years[^1]. Many disciplines around the world are incorporating the knowledge of data science in their day to operations. The skills employers most frequently seek in data science job posting are `Python`, `R`, and `SQL`. It is hoped that the preliminary discussion in this project will help you to get some idea about `Python` in data science. \n\n\n\n[^1]:https://www.techrepublic.com/article/why-data-scientist-is-the-most-promising-job-of-2019/\n","srcMarkdownNoYaml":"\n\n```{r}\n#| include: false\nlibrary(reticulate)\nSys.unsetenv(\"RETICULATE_PYTHON\")\nreticulate::use_virtualenv(\"C:\\\\Users\\\\mshar\\\\OneDrive - Southern Illinois University\\\\BSAN405_MLINBUSINESS_WEBSITE\\\\mlbusiness2\")\n```\n\n\n# Introduction \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The objective of this document is to introduce the necessary functions from `pandas` library in `Python` for data manipulation and `matplotlib` and `seaborn` libraries for data visualization. There are basically six functions - `select()`, `filter()`, `mutate()`, `arrange()`, `group_by()`, and `summarize()` - from `dplyr` package of `tidyverse` ecosystem that are very much necessary for data manipulation. These six functions can be used for 80% of data manipulation problems. In this document, we will compare the above six functions from `dplyr` with the equivalent `pandas` functions. Additionally, this handout also compares some other Python packages, particularly `plotnine` library that can be used to apply `ggplot` in Python.\n\n\n# Loading Necessary Python Packages \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Python` programming in `RMarkdown` is used to analyse the data. In some cases, the `R Programming`is also used. In this section, the necessary `python` packages/modules are imported. \n\n```{python}\n#| warning: false\nimport pandas as pd # For Data Manipulation\nimport numpy as np # For Data Manipulation\nimport matplotlib.pyplot as plt # For Visualization \n\nimport seaborn as sns # For Visualization \nimport sklearn # For Machine Learning \n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n# Plotnine is a clone of ggplot2 in R\nfrom plotnine import *\n# lets-plot is another clone of ggplot2\n# from lets_plot import *\n```\n\n\n# Setting/Changing Working Directory \n\n```{python}\n#| eval: false\nimport os\nos.getcwd()\nos.listdir()\n```\n\n\n# Importing the Dataset \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Being able to import the dataset into your text editor or IDE such as VS Code or RStudio is an important data analytics skill. Data reside in many places and in many forms. Different kinds of data from different sources need to be imported. For example - you can import a dataset from your local machine or website or database. Sometimes, we need to import data from social media such as Twitter, Youtube and Facebook. Therefore, knowing how to import data from many different sources is a very critical skill of data scientists. \n\n\n```{python}\n# Importing Dataset \nproduct = pd.read_csv(\n  \"https://raw.githubusercontent.com/msharifbd/DATA/main/Al-Bundy_raw-data.csv\")\n\n```\n\n# Learning About the Metadata \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Metadata is data about data. Once we import a dataset into our text editor, we need to study the dataset very well. For example - we need to know how many features and cases the dataset has. We also need to know the types of the features. Many types the features are not in appropriate type; then, we need to change them into appropriate type. Moreover, we need to check whether the dataset contains missing data and make decision about how to deal with those missing data. To sum up, learning about the metadata is a very important step before you start processing your data.\n\n\n```{python}\n# Metadata of the dataset \nproduct.shape\n\nprint('The total number of rows and columns of the product data is \\\n{} and {} respectively.'.format(product.shape[0], product.shape[1]))\n\nproduct.count()[0] # counting the number of rows in the dataset\n\n```\n\n\n\n```{python}\nproduct.columns\nproduct.dtypes\n```\n\n\n\n```{python}\nproduct.head()\n```\n\n```{python}\nproduct.info()\n```\n\n# Cleaning the Dataset \n\n```{python}\n# Changing the names of the columns to uppercase \nproduct.rename(columns = str.upper, inplace = True)\nproduct.columns\n```\n\n\n```{python}\nnew_column = product.columns \\\n    .str.replace(\"(\", '').str.replace(\")\", \"\") \\\n    .str.replace(' ','_') # Cleaning the names of the variables \nnew_column\n```\n\n```{python}\n# Replacing whitespace in the names of the variables \ncol_name = product.columns.str.replace(' ','_')\nproduct.info()\n```\n\n\n\n```{python}\nproduct.columns = new_column # Changing all column names \nproduct.info()\nproduct.head()\n```\n\n\n## Changing the Types of the Variables \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are several types of data in Python as it is in R. Table @tbl-table1 lists the data types in python.\n\n```{r}\n#| include: false\nlibrary(kableExtra)\ndata_types = tibble::tribble(\n  ~`Python Data Type`, ~`Data Nature`, \n  'float64', 'Real Numbers',\n  'category', 'cateogries',\n  'datetime64', 'Date Times',\n  'int64', 'Integers',\n  'bool', 'True or False',\n  'string', 'Text'\n)\n\n\n```\n\n\n```{r}\n#| label: tbl-table1\n#| echo: false\n# These are R code to prepare Table 2 using KableExtra \nkbl(data_types, booktabs = TRUE, \n    caption = \"Types of Data in Python\") %>% \n  kable_styling(latex_options = c ('striped', 'hold_positions'))\n```\n\n\n\n\n```{python}\n# Changing the DATE variable from object to date\nproduct['DATE'] = pd.to_datetime(product['DATE']) \nproduct.info()\n```\n\n```{python}\n# converting integer to object\nproduct.INVOICENO = product.INVOICENO.astype(str) \nproduct[['MONTH', 'PRODUCTID']] = product[['MONTH', 'PRODUCTID']].astype(str) \nproduct.info()\n```\n\n# `Tidyverse` and `Pandas` Eqivalent Functions \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table @tbl-table2 compares the `tidyverse` and `pandas` equivalent functions. These functions are very much important to perform data analysis in both `R` and `Python`. \n\n```{r}\n#| include: false\ntidyverse_pandas = tibble::tribble(\n  ~`tidyverse function`, ~`pandas function`, \n  'filter ()', 'query ()',\n  'arrange ()', 'sort_values ()',\n  'select ()', 'filter () or loc ()',\n  'rename ()', 'rename ()',\n  'mutate ()', 'assign ()',\n  'group_by ()', 'groupby ()',\n  'summarize ()', 'agg ()'\n)\n\n```\n\n```{r}\n#| echo: false\n#| label: tbl-table2\n# These are R code to prepare Table 2 using KableExtra \nkbl(tidyverse_pandas, booktabs = TRUE, \n    caption = \"Tidyverse and Pandas Equivalent Functions\") %>% \n  kable_styling(latex_options = c ('striped', 'hold_positions'))\n```\n\n\n## `select ()` Equivalent in Python - Accessing Columns \n\n```{python}\nprod2 = product[['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\nprod2.head()\n```\n\n\n```{python}\nproduct.loc[:,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\n\nproduct.loc[0:5,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]\n```\n\n\n\n```{python}\nproduct.filter(['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE'])\n```\n\n```{python}\n# Regular Expression (Regex)\nproduct.filter(regex = \"PRICE$\") # Ends with Price \nproduct.filter(regex = \"^SIZE\")  # Starts with SIZE\nproduct.filter(regex = \"PRICE\")  # Contains the word Price \n```\n\n\n\n```{python}\nproduct.select_dtypes('object')\nproduct.select_dtypes('int')\n```\n\n\n```{python}\nproduct.loc[:,product.columns.str.startswith('SIZE')]\nproduct.loc[:,product.columns.str.contains('PRICE')]\nproduct.loc[:,product.columns.str.endswith('PRICE')]\n```\n\n\n\n```{python}\n# Dropping some columns \nproduct.info()\nproduct.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1)\nproduct.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1) \\\n    .pipe(lambda x: x.info())\n```\n\n### Rearranging Columns \n\n```{python}\n# Sorting Alphabetically\nproduct.reindex(sorted(product.columns), axis = 1)\n# Sorting As You Want (ASY)\nproduct.columns.to_list()\ncol_first = ['YEAR','MONTH']\ncol_rest = product.columns.difference(col_first, sort=False).to_list()\nproduct2 = product[col_first + col_rest]\nproduct2.info()\n```\n\n\n## `filter ()` Equivalent in Python - Accessing Rows \n\n```{python}\nproduct.info()\nproduct.COUNTRY.value_counts()\nproduct['YEAR'].unique()\nproduct['YEAR'].value_counts()\n```\n\n\n```{python}\nproduct.query('COUNTRY == \"United States\"')\nproduct.query('COUNTRY == \"United States\" | COUNTRY == \"Canada\"')\nproduct.query(\"COUNTRY in ['United States', 'Canada']\")\n\nproduct.query(\"COUNTRY == 'United States' & YEAR == 2016\")\nproduct.query(\"COUNTRY == 'United States' & YEAR in [2015,2016]\")\n```\n\n\n\n```{python}\nproduct.loc[(product['COUNTRY'] == \"United States\")]\nproduct.loc[product['COUNTRY'].isin([\"United States\", \"Canada\"])]\nproduct.loc[product['COUNTRY'] \\\n  .isin([\"United States\", \"Canada\"]) & (product['YEAR'] == 2014)]\nproduct.loc[(product['COUNTRY'] == \"United States\") & (product[\"YEAR\"] == 2014)]\n```\n### `loc[]` Function can be used both for Slicing (selecting Rows) and Selecting Columns\n\n```{python}\nproduct.loc[\n  product['COUNTRY'] == 'United States',\n  ['COUNTRY', \"UNITPRICE\", \"SALEPRICE\"]]\n```\n\n## `arrange ()` Equivalent in Python - Sorting or Arranging Rows \n\n```{python}\nproduct.sort_values(by = ['MONTH'])\nproduct.sort_values(by = ['MONTH'], ascending = False)\nproduct.sort_values(by = ['MONTH', 'SALEPRICE'])\n```\n\n## `rename ()` Equivalent in Python - Renaming Column Names\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We already did some renaming of the columns using `str.` function. Here we use `rename ()` function to change the name of the columns. \n\n```{python}\nproduct.info()\nproduct.rename( columns = \n  {'SIZE_(EUROPE)': 'SIZE_EUROPE',\n   'SIZE_(UK)' : 'SIZE_UK'}) \\\n   .pipe(lambda x: x.info())\n```\n\n## `mutate ()` Equivalent in Python - Creating New Columns (Variables)\n\n```{python}\nproduct['NECOLUMN'] = 5\nproduct.head()\nproduct.drop(columns = ['NECOLUMN'], axis = 1, inplace = True) \n```\n\n\n```{python}\nproduct['SALEPRICE2'] = product['UNITPRICE']*(1-product['DISCOUNT'])\nproduct.info()\n```\n\n\n```{python}\n# Using the assign () function \nproduct[['PRODUCTID', 'UNITPRICE', 'DISCOUNT']] \\\n .assign(SALEPRICE3 = lambda x: x.UNITPRICE*(1-x.DISCOUNT)) \\\n .head(5)\n```\n\n## `group_by ()` and `summarize ()` Equivalent in Python - Summarizing Data \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Figure @fig-groupbyplot presents the split-apply-combine principle in `group_by ()` and `summarize ()` functions. \n\n\n```{r}\n#| echo: false\n#| label: fig-groupbyplot\n#| fig-cap: \"Split Apply and Combine Principle\"\n#| fig-align: center\nknitr::include_graphics(\"images/split-apply-combine.png\")\n```\n\n\n```{python}\nproduct.info()\nproduct.groupby(['COUNTRY']) ['UNITPRICE'].mean()\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']].mean()\n\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(np.mean)\n\nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(\"mean\")\n       \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"))\n            \n            \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"),\n            TOTALN = (\"SALEPRICE\", \"size\"), # size function for n\n            TOTALOBS = (\"SALEPRICE\", \"count\") # count function for n\n            )\n\n\n# Combining Several Pandas Functions together           \nproduct.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n       .agg(AVG_UNITPRICE = (\"UNITPRICE\", \"mean\"), \n            AVG_LISTPRICE = (\"SALEPRICE\", \"mean\"),\n            TOTALN = (\"SALEPRICE\", \"size\"), # size function for n\n            TOTALOBS = (\"SALEPRICE\", \"count\") # count function for n\n            ) \\\n       .sort_values(by = ['TOTALOBS'], ascending = False) \\\n       .reset_index() \\\n       .query ('COUNTRY == \"United States\"')\n\n```\n\n\n## Summary Statistics in Python \n\n```{python}\n# Summary Statistics in Python \nproduct.GENDER.value_counts()\n# Encoding a Categorical Variables \nproduct['SEX'] = product['GENDER'].map({\n  'Male':1,\n  'Female':0\n})\n\n\n# Defining a Function \ndef percentile(n):\n    def percentile_(x):\n        return x.quantile(n)\n    percentile_.__name__ = 'percentile_{:02.0f}'.format(n*100)\n    return percentile_\n  \nproduct [['SALEPRICE', 'UNITPRICE', 'SEX']] \\\n     .agg([\"count\",\"mean\", \"std\", \"median\", percentile(0.25), percentile(0.75)]) \\\n     .transpose () \\\n     .reset_index() \\\n     .rename(columns = {'index': \"Variables\",\n                        'percentile_25': 'P25',\n                        'percentile_75': 'P75',\n                        'count': 'n',\n                        'mean' : 'Mean',\n                        'median' : 'Median',\n                        'std': 'Std'\n                       }) \\\n      .round(3) # rounding to two decimal places \n\n```\n\n\n\n# Reshaping Data \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Two functions are widely used in python to reshape data. These functions are - `melt ()` and `pivot ()`, which are equivalent to `pivot_longer ()` and `pivot_wider ()` in R. \n\n```{python}\npd.__version__ # 2.2.3\n```\n\n\n```{python}\nproduct[['PRODUCTID','GENDER']].value_counts()\n\nreshape = product[['PRODUCTID','GENDER']] \\\n          .value_counts() \\\n          .reset_index(name = 'COUNTS') \\\n          .pivot(index = 'PRODUCTID', columns = 'GENDER', values = \"COUNTS\") \\\n          .assign (TOTALSALES = lambda x: x.Female + x.Male) \\\n          .sort_values (by = ['TOTALSALES'], ascending = False) \\\n          .reset_index() \n          \nreshape.head(5)\n```\n\n\n# Data Visualization \n\n## Bar Chart \n```{python}\n#| warning: false\n#| fig-align: center\n#| fig-cap: \"Total Observations of Countries\"\n\nbar_r = product.filter (['COUNTRY']) \\\n       .value_counts() \\\n       .reset_index() \\\n       .rename (columns = {'count':'n'}) \\\n       .sort_values (by = ['n'])\n\n(ggplot(data = bar_r, \n  mapping = aes(x = 'COUNTRY', y = 'n'))+\n  geom_bar (fill = \"pink\", stat = \"identity\")+\n  labs (x = 'Country',\n  y = 'Number of Observations'\n  #,title = 'Total Observations of Countries'\n  )\n)\n\n```\n\n## Line Chart \n\n```{python}\n#| warning: false\n#| fig-cap: \"Relations between Shoe Size and Sale Price in Different Countries\"\n#| fig-align: center\n\n(ggplot(product, aes(x = 'SIZE_US', y= 'UNITPRICE', color = 'GENDER'))+\n facet_wrap('COUNTRY')+\n geom_smooth(se = False, method = 'lm')+\n labs(x = \"Shoe Size (US)\", y = \"Price\")+\n theme (legend_position = \"top\")\n)\n\n```\n\n```{python}\n#| warning: false\n#| fig-cap: \"Sales of Shoe in Different Months\"\n#| fig-align: center\n\nmonth_sales = product['MONTH'] \\\n    .value_counts(sort = False) \\\n    .reset_index(name = 'SALES') \\\n    .rename (columns = {'index' : 'MONTH'})\n\nmonth_sales['MONTH'] = pd.to_numeric(month_sales['MONTH']) \n\n(ggplot(month_sales, aes (\"MONTH\", \"SALES\"))\n + geom_point(color = 'blue')\n + labs(x = \"Month\", y = \"Total Sales\"\n   #,title = \"SALES IN DIFFERENT MONTHS\"\n   )\n)\n```\n\n# Conclusion \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data science is the number 1 most promising job in the US in recent years[^1]. Many disciplines around the world are incorporating the knowledge of data science in their day to operations. The skills employers most frequently seek in data science job posting are `Python`, `R`, and `SQL`. It is hoped that the preliminary discussion in this project will help you to get some idea about `Python` in data science. \n\n\n\n[^1]:https://www.techrepublic.com/article/why-data-scientist-is-the-most-promising-job-of-2019/\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":5,"number-sections":true,"output-file":"python_eda.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","theme":"solar","light":"flatly","title":"<center> Exploratory Data Analysis in Python","toc-title":"Table of Contents","mainfont":"emoji"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}