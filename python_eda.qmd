---
title: "<center> Exploratory Data Analysis in Python"
format: 
  html: 
    toc: true
    #toc-title: Table of Contents 
    toc-depth: 5
    number-sections: true
    mainfont: emoji
engine: knitr
---

```{r}
#| include: false
library(reticulate)
Sys.unsetenv("RETICULATE_PYTHON")
reticulate::use_virtualenv("C:\\Users\\mshar\\OneDrive - Southern Illinois University\\BSAN405_MLINBUSINESS_WEBSITE\\mlbusiness2")
```


# Introduction 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The objective of this document is to introduce the necessary functions from `pandas` library in `Python` for data manipulation and `matplotlib` and `seaborn` libraries for data visualization. There are basically six functions - `select()`, `filter()`, `mutate()`, `arrange()`, `group_by()`, and `summarize()` - from `dplyr` package of `tidyverse` ecosystem that are very much necessary for data manipulation. These six functions can be used for 80% of data manipulation problems. In this document, we will compare the above six functions from `dplyr` with the equivalent `pandas` functions. Additionally, this handout also compares some other Python packages, particularly `plotnine` library that can be used to apply `ggplot` in Python.


# Loading Necessary Python Packages 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Python` programming in `RMarkdown` is used to analyse the data. In some cases, the `R Programming`is also used. In this section, the necessary `python` packages/modules are imported. 

```{python}
#| warning: false
import pandas as pd # For Data Manipulation
import numpy as np # For Data Manipulation
import matplotlib.pyplot as plt # For Visualization 

import seaborn as sns # For Visualization 
import sklearn # For Machine Learning 

import warnings 
warnings.filterwarnings('ignore')

# Plotnine is a clone of ggplot2 in R
from plotnine import *
# lets-plot is another clone of ggplot2
# from lets_plot import *
```


# Setting/Changing Working Directory 

```{python}
#| eval: false
import os
os.getcwd()
os.listdir()
```


# Importing the Dataset 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Being able to import the dataset into your text editor or IDE such as VS Code or RStudio is an important data analytics skill. Data reside in many places and in many forms. Different kinds of data from different sources need to be imported. For example - you can import a dataset from your local machine or website or database. Sometimes, we need to import data from social media such as Twitter, Youtube and Facebook. Therefore, knowing how to import data from many different sources is a very critical skill of data scientists. 


```{python}
# Importing Dataset 
product = pd.read_csv(
  "https://raw.githubusercontent.com/msharifbd/DATA/main/Al-Bundy_raw-data.csv")

```

# Learning About the Metadata 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Metadata is data about data. Once we import a dataset into our text editor, we need to study the dataset very well. For example - we need to know how many features and cases the dataset has. We also need to know the types of the features. Many types the features are not in appropriate type; then, we need to change them into appropriate type. Moreover, we need to check whether the dataset contains missing data and make decision about how to deal with those missing data. To sum up, learning about the metadata is a very important step before you start processing your data.


```{python}
#| warning: false
# Metadata of the dataset 
product.shape

print('The total number of rows and columns of the product data is \
{} and {} respectively.'.format(product.shape[0], product.shape[1]))

product.count()[0] # counting the number of rows in the dataset

```



```{python}
product.columns
product.dtypes
```



```{python}
product.head()
```

```{python}
product.info()
```

# Cleaning the Dataset 

```{python}
# Changing the names of the columns to uppercase 
product.rename(columns = str.upper, inplace = True)
product.columns
```


```{python}
new_column = product.columns \
    .str.replace("(", '').str.replace(")", "") \
    .str.replace(' ','_') # Cleaning the names of the variables 
new_column
```

```{python}
# Replacing whitespace in the names of the variables 
col_name = product.columns.str.replace(' ','_')
product.info()
```



```{python}
product.columns = new_column # Changing all column names 
product.info()
product.head()
```


## Changing the Types of the Variables 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are several types of data in Python as it is in R. Table @tbl-table1 lists the data types in python.

```{r}
#| include: false
library(kableExtra)
data_types = tibble::tribble(
  ~`Python Data Type`, ~`Data Nature`, 
  'float64', 'Real Numbers',
  'category', 'cateogries',
  'datetime64', 'Date Times',
  'int64', 'Integers',
  'bool', 'True or False',
  'string', 'Text'
)


```


```{r}
#| label: tbl-table1
#| echo: false
# These are R code to prepare Table 2 using KableExtra 
kbl(data_types, booktabs = TRUE, 
    caption = "Types of Data in Python") %>% 
  kable_styling(latex_options = c ('striped', 'hold_positions'))
```




```{python}
# Changing the DATE variable from object to date
product['DATE'] = pd.to_datetime(product['DATE']) 
product.info()
```

```{python}
# converting integer to object
product.INVOICENO = product.INVOICENO.astype(str) 
product[['MONTH', 'PRODUCTID']] = product[['MONTH', 'PRODUCTID']].astype(str) 
product.info()
```

# `Tidyverse` and `Pandas` Eqivalent Functions 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table @tbl-table2 compares the `tidyverse` and `pandas` equivalent functions. These functions are very much important to perform data analysis in both `R` and `Python`. 

```{r}
#| include: false
tidyverse_pandas = tibble::tribble(
  ~`tidyverse function`, ~`pandas function`, 
  'filter ()', 'query ()',
  'arrange ()', 'sort_values ()',
  'select ()', 'filter () or loc ()',
  'rename ()', 'rename ()',
  'mutate ()', 'assign ()',
  'group_by ()', 'groupby ()',
  'summarize ()', 'agg ()'
)

```

```{r}
#| echo: false
#| label: tbl-table2
# These are R code to prepare Table 2 using KableExtra 
kbl(tidyverse_pandas, booktabs = TRUE, 
    caption = "Tidyverse and Pandas Equivalent Functions") %>% 
  kable_styling(latex_options = c ('striped', 'hold_positions'))
```


## `select ()` Equivalent in Python - Accessing Columns 

```{python}
prod2 = product[['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]
prod2.head()
```


```{python}
product.loc[:,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]

product.loc[0:5,['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE']]
```



```{python}
product.filter(['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE'])
```

```{python}
# Regular Expression (Regex)
product.filter(regex = "PRICE$") # Ends with Price 
product.filter(regex = "^SIZE")  # Starts with SIZE
product.filter(regex = "PRICE")  # Contains the word Price 
```



```{python}
product.select_dtypes('object')
product.select_dtypes('int')
```


```{python}
product.loc[:,product.columns.str.startswith('SIZE')]
product.loc[:,product.columns.str.contains('PRICE')]
product.loc[:,product.columns.str.endswith('PRICE')]
```



```{python}
# Dropping some columns 
product.info()
product.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1)
product.drop(columns = ['SIZE_EUROPE', 'SIZE_UK'], axis = 1) \
    .pipe(lambda x: x.info())
```

### Rearranging Columns 

```{python}
# Sorting Alphabetically
product.reindex(sorted(product.columns), axis = 1)
# Sorting As You Want (ASY)
product.columns.to_list()
col_first = ['YEAR','MONTH']
col_rest = product.columns.difference(col_first, sort=False).to_list()
product2 = product[col_first + col_rest]
product2.info()
```


## `filter ()` Equivalent in Python - Accessing Rows 

```{python}
product.info()
product.COUNTRY.value_counts()
product['YEAR'].unique()
product['YEAR'].value_counts()
```


```{python}
product.query('COUNTRY == "United States"')
product.query('COUNTRY == "United States" | COUNTRY == "Canada"')
product.query("COUNTRY in ['United States', 'Canada']")

product.query("COUNTRY == 'United States' & YEAR == 2016")
product.query("COUNTRY == 'United States' & YEAR in [2015,2016]")
```



```{python}
product.loc[(product['COUNTRY'] == "United States")]
product.loc[product['COUNTRY'].isin(["United States", "Canada"])]
product.loc[product['COUNTRY'] \
  .isin(["United States", "Canada"]) & (product['YEAR'] == 2014)]
product.loc[(product['COUNTRY'] == "United States") & (product["YEAR"] == 2014)]
```
### `loc[]` Function can be used both for Slicing (selecting Rows) and Selecting Columns

```{python}
product.loc[
  product['COUNTRY'] == 'United States',
  ['COUNTRY', "UNITPRICE", "SALEPRICE"]]
```

## `arrange ()` Equivalent in Python - Sorting or Arranging Rows 

```{python}
product.sort_values(by = ['MONTH'])
product.sort_values(by = ['MONTH'], ascending = False)
product.sort_values(by = ['MONTH', 'SALEPRICE'])
```

## `rename ()` Equivalent in Python - Renaming Column Names

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We already did some renaming of the columns using `str.` function. Here we use `rename ()` function to change the name of the columns. 

```{python}
product.info()
product.rename( columns = 
  {'SIZE_(EUROPE)': 'SIZE_EUROPE',
   'SIZE_(UK)' : 'SIZE_UK'}) \
   .pipe(lambda x: x.info())
```

## `mutate ()` Equivalent in Python - Creating New Columns (Variables)

```{python}
product['NECOLUMN'] = 5
product.head()
product.drop(columns = ['NECOLUMN'], axis = 1, inplace = True) 
```


```{python}
product['SALEPRICE2'] = product['UNITPRICE']*(1-product['DISCOUNT'])
product.info()
```


```{python}
# Using the assign () function 
product[['PRODUCTID', 'UNITPRICE', 'DISCOUNT']] \
 .assign(SALEPRICE3 = lambda x: x.UNITPRICE*(1-x.DISCOUNT)) \
 .head(5)
```

## `group_by ()` and `summarize ()` Equivalent in Python - Summarizing Data 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Figure @fig-groupbyplot presents the split-apply-combine principle in `group_by ()` and `summarize ()` functions. 


```{r}
#| echo: false
#| label: fig-groupbyplot
#| fig-cap: "Split Apply and Combine Principle"
#| fig-align: center
knitr::include_graphics("images/split-apply-combine.png")
```


```{python}
product.info()
product.groupby(['COUNTRY']) ['UNITPRICE'].mean()
product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']].mean()

product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \
       .agg(np.mean)

product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \
       .agg("mean")
       
product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \
       .agg(AVG_UNITPRICE = ("UNITPRICE", "mean"), 
            AVG_LISTPRICE = ("SALEPRICE", "mean"))
            
            
product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \
       .agg(AVG_UNITPRICE = ("UNITPRICE", "mean"), 
            AVG_LISTPRICE = ("SALEPRICE", "mean"),
            TOTALN = ("SALEPRICE", "size"), # size function for n
            TOTALOBS = ("SALEPRICE", "count") # count function for n
            )


# Combining Several Pandas Functions together           
product.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \
       .agg(AVG_UNITPRICE = ("UNITPRICE", "mean"), 
            AVG_LISTPRICE = ("SALEPRICE", "mean"),
            TOTALN = ("SALEPRICE", "size"), # size function for n
            TOTALOBS = ("SALEPRICE", "count") # count function for n
            ) \
       .sort_values(by = ['TOTALOBS'], ascending = False) \
       .reset_index() \
       .query ('COUNTRY == "United States"')

```


## Summary Statistics in Python 

```{python}
# Summary Statistics in Python 
product.GENDER.value_counts()
# Encoding a Categorical Variables 
product['SEX'] = product['GENDER'].map({
  'Male':1,
  'Female':0
})


# Defining a Function 
def percentile(n):
    def percentile_(x):
        return x.quantile(n)
    percentile_.__name__ = 'percentile_{:02.0f}'.format(n*100)
    return percentile_
  
product [['SALEPRICE', 'UNITPRICE', 'SEX']] \
     .agg(["count","mean", "std", "median", percentile(0.25), percentile(0.75)]) \
     .transpose () \
     .reset_index() \
     .rename(columns = {'index': "Variables",
                        'percentile_25': 'P25',
                        'percentile_75': 'P75',
                        'count': 'n',
                        'mean' : 'Mean',
                        'median' : 'Median',
                        'std': 'Std'
                       }) \
      .round(3) # rounding to two decimal places 

```



# Reshaping Data 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Two functions are widely used in python to reshape data. These functions are - `melt ()` and `pivot ()`, which are equivalent to `pivot_longer ()` and `pivot_wider ()` in R. 

```{python}
pd.__version__ # 2.2.3
```


```{python}
product[['PRODUCTID','GENDER']].value_counts()

reshape = product[['PRODUCTID','GENDER']] \
          .value_counts() \
          .reset_index(name = 'COUNTS') \
          .pivot(index = 'PRODUCTID', columns = 'GENDER', values = "COUNTS") \
          .assign (TOTALSALES = lambda x: x.Female + x.Male) \
          .sort_values (by = ['TOTALSALES'], ascending = False) \
          .reset_index() 
          
reshape.head(5)
```


# Data Visualization 

## Bar Chart 
```{python}
#| warning: false
#| fig-align: center
#| fig-cap: "Total Observations of Countries"

bar_r = product.filter (['COUNTRY']) \
       .value_counts() \
       .reset_index() \
       .rename (columns = {'count':'n'}) \
       .sort_values (by = ['n'])

plot = (ggplot(data = bar_r, 
  mapping = aes(x = 'COUNTRY', y = 'n'))+
  geom_bar (fill = "pink", stat = "identity")+
  labs (x = 'Country',
  y = 'Number of Observations'
  #,title = 'Total Observations of Countries'
  )
)
plot.draw(True)
```

## Line Chart 

```{python}
#| warning: false
#| fig-cap: "Relations between Shoe Size and Sale Price in Different Countries"
#| fig-align: center

plot = (ggplot(product, aes(x = 'SIZE_US', y= 'UNITPRICE', color = 'GENDER'))+
 facet_wrap('COUNTRY')+
 geom_smooth(se = False, method = 'lm')+
 labs(x = "Shoe Size (US)", y = "Price")+
 theme (legend_position = "top")
)
plot.draw(True)
```

```{python}
#| warning: false
#| fig-cap: "Sales of Shoe in Different Months"
#| fig-align: center

month_sales = product['MONTH'] \
    .value_counts(sort = False) \
    .reset_index(name = 'SALES') \
    .rename (columns = {'index' : 'MONTH'})

month_sales['MONTH'] = pd.to_numeric(month_sales['MONTH']) 

plot = (ggplot(month_sales, aes ("MONTH", "SALES"))
 + geom_point(color = 'blue')
 + labs(x = "Month", y = "Total Sales"
   #,title = "SALES IN DIFFERENT MONTHS"
   )
)
plot.draw(True)
```

# Conclusion 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data science is the number 1 most promising job in the US in recent years[^1]. Many disciplines around the world are incorporating the knowledge of data science in their day to operations. The skills employers most frequently seek in data science job posting are `Python`, `R`, and `SQL`. It is hoped that the preliminary discussion in this project will help you to get some idea about `Python` in data science. 



[^1]:https://www.techrepublic.com/article/why-data-scientist-is-the-most-promising-job-of-2019/
